{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c63bb0b-ba30-410c-a62e-63223a3ec803",
   "metadata": {},
   "source": [
    "# Lecture - Data Splitting\n",
    "#### STAT 450"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "743f13dc-f4be-4162-8bba-d69e2c26e1e2",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "By the end of this lecture, students will be able to:\n",
    "\n",
    "- Discuss how the research question being asked impacts the statistical modelling procedures.\n",
    "- Write a computer script to perform post-lasso and use it to estimate a generative model.\n",
    "- Discuss post-selection problems (e.g., double dipping into the data set) and current practical solutions available to address these (e.g., data-splitting techniques).\n",
    "- Write a computer script to apply currently available practical solutions to post-selection problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de45ef1-8060-4c07-a271-27b4714b0082",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(broom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca077a8-5ccd-42d8-ae86-3ec191b52099",
   "metadata": {},
   "source": [
    "# Part I - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4941ef-8f21-4ade-8b36-d460963f9aad",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-033bcebb28d726f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Statistical Modelling: Inference vs Prediction\n",
    "\n",
    "In statistical modelling, the objective is to capture how a response variable, $Y$, is associated with a set of input variables, $\\mathbf{X}=\\left(X_1, X_2, ..., X_p\\right)$. Two main reasons motivate us to model the relationship between $\\mathbf{X}$ and $Y$: (1) prediction and (2) inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ac11d-83fe-4107-8f2a-7f6cd6aa122c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7cbc7f723e3a6e0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Prediction\n",
    "\n",
    "- Statistical modelling allows us to model the relationship between the response variable and the covariates associated with it based on data. \n",
    "\n",
    "- Statistical modelling also gives you a measure of uncertainty, which is crucial. \n",
    "\n",
    "- A few examples of questions questions that can be answered with prediction: \n",
    "\n",
    "  - How much will be the selling price of a house with three bedrooms, 1300 sq. feet in Kitsilano? \n",
    "  - Given that my blood albumin level is 44g/L, do I have a liver problem?\n",
    "  - What will be my final grade in STAT 450, given that I'm studying 5 hours per week and got 85% on the homework? \n",
    "  - Is there a difference in final grades between two sessions of a course: one online and the other in-person? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e8e5bb-c338-4d2f-b8a2-1c26916d61d4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c79321fbf3f5ae6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Linear Regression as a Predictor\n",
    "\n",
    "- The conditional expectation is the best predictor of $Y$ given a vector of variables $\\boldsymbol{X}$: $E[Y|\\boldsymbol{X}]$ -- best in the sense of Mean Square Error. \n",
    "\n",
    "\n",
    "- An LR assumes a linear form (linear in the parameters) for the conditional expectation\n",
    "    - In general, this is only an *assumed* model, an *approximation* to the real form of $E[Y|\\boldsymbol{X}]$\n",
    "\n",
    "\n",
    "- If the conditional expectation is not linear, the LR can still be used as a predictor of $Y$, but it may not be the *best* one!\n",
    "    - More flexible models (e.g., kNN) could perform better to estimate the conditional expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be1013-9b87-44e2-9010-d3cca77d09db",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f82dbc9d8ca82a74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23659750-1d37-47d9-9545-28f983887e5b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b915335777ccfac9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- In some cases, we are more interested in understanding the association between $Y$ and $\\mathbf{X}$ than in predicting $Y$ based on $\\mathbf{X}$. \n",
    "  - We want to know how $Y$ varies when $\\mathbf{X}$ changes. \n",
    "\n",
    "\n",
    "- For example:\n",
    "  - How does price affect the sales of iPhones?\n",
    "  - What affects the price of a house more: the number of bedrooms or the number of bathrooms? \n",
    "  - Is $\\text{CO}_2$ levels associated with temperature elevation? \n",
    "  - Does the sex of the applicants influence the chance of admission at the University of British Columbia?\n",
    "  - Has the social distancing measures influenced the spread of COVID-19 in Canada?\n",
    "\n",
    "\n",
    "- In all the questions above, we are not primarily interested in making highly accurate predictions. Instead, we want to understand the relation between different variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784c1fc-2da1-4029-a82f-5bde984f692d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a882ef3033dc2526",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240d7c2-d829-41f9-b375-b4482f6005cf",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d310f75b7d923b53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- In many cases, we are interested in both inference and prediction. \n",
    "  - For example, one could be interested in answering, \"How do social distancing measures influence the spread of COVID-19?\" but also in answering, \"How many cases can we expect to have if we implement some social distancing policies?\".   \n",
    "  - Linear Models are an excellent initial approach in these cases, as they are highly interpretable and perform reasonably well in many cases. \n",
    "\n",
    "\n",
    "- As we move to more complex models non-linear models, such as LOESS or even Neural Networks, we **might** obtain much higher prediction performance, but their interpretation is quite tricky, if possible at all.  \n",
    "    - These models can be advantageous if we are only interested in accurate predictions. \n",
    "    - For example, a bakery manager wants to know how many apple pies will be sold the next day in order to know how many to prepare today. In this case, it doesn't matter how they get the prediction as long as it is close. Otherwise, they miss sales if the forecast is too small; they lose money by throwing out too many pies if the forecast is too high. No matter how complex these models are, we can always estimate their prediction performance. \n",
    "\n",
    "\n",
    "- When our primary interest is in inference, i.e., in understanding the relationship between the response and the covariates, we are willing to sacrifice some prediction performance for a more interpretable model that correctly depicts the variables' relationship. \n",
    "  - We are concerned about obtaining good estimates for the parameters of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7df6c6-7028-4cda-8277-72e44d5e578f",
   "metadata": {},
   "source": [
    "- No matter the objective, prediction or inference, model assessment is of fundamental importance. \n",
    "    - Key strategy for model assessment: data splitting. \n",
    "    - Data splitting is widespread for evaluating a model's prediction performance. But as it turns out, it can also be very useful for inference! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0764d-23b6-4611-a024-4c073330f806",
   "metadata": {},
   "source": [
    "# Part II - Double Dipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086cb5d-275f-4f5e-80e7-4888f3fefe37",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4db8971f16f54c5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2. Model Selection and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76082b5-261b-4d79-9862-d78e6fc55849",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52b0432e6c14a90f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "- There are many aspects involved in selecting a model that goes beyond variable selection; for example,\n",
    "  - Do we want a parametric or non-parametric approach? \n",
    "  - Do we want to assume a functional form for the relationship between $Y$ and $\\mathbf{X}$ (e.g., linear, quadratic, exponential, logarithmic)?\n",
    "  - Prediction performance. \n",
    "  - Is model interpretability important?\n",
    "\n",
    "\n",
    "- Let's focus on selecting Multiple Linear Regression models, which comes down to variable selection.\n",
    "\n",
    "\n",
    "- There are many ways of comparing models: (1) $C_p$; (2) AIC; (3) BIC; (4) F-test; and (5) cross-validation MSE.\n",
    "\n",
    "\n",
    "- and different techniques to select a desired model:\n",
    "  - Stepwise Algorithms (e.g., Forward Selection, Backward Selection)\n",
    "  - Lasso\n",
    "\n",
    "### 2.1 Can we still make inferences for the selected models??\n",
    "\n",
    "- You have learned how to make inferences (e.g., calculate the confidence interval and hypotheses tests) for a **fixed model**.\n",
    "\n",
    "\n",
    "- When we apply any of these model selection methods, we are searching for the combination of variables that will give us the best model (according to a given metric). \n",
    "  - So, the variables in our final models are not fixed; instead, they are selected adaptively based on **the data at hand**. \n",
    "\n",
    "<br>\n",
    "\n",
    "- Two questions arise then: \n",
    "  1. Do these model selection algorithms affect the inference about the parameters of the model? \n",
    "  2. Is the way we interpret the models still the same? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514e5e66-2324-4ac7-953b-ab682189ff4e",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.1.1 Forward Selection Review\n",
    "Suppose we have $p$ covariates $X_1, X_2,\\ldots,X_p$ to explain our response $Y$. The full model is given by:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_{i1} + \\ldots + \\beta_p X_{ip} + \\varepsilon\n",
    "$$\n",
    "\n",
    "We want to find the best subset of variables to explain $Y$. Searching the best subset using brute force would require us to fit a prohibitive number of models to compare (see table below).\n",
    "\n",
    "| number of covariates (*p*) | Number of possible models |\n",
    "| ---------------------------|-------------------:|\n",
    "| 10 | 1,024 |\n",
    "| 20 | 1,048,576 |\n",
    "| 30 | 1,073,741,824 |\n",
    "\n",
    "\n",
    "The forward selection strategy helps us find good models among the insane number of models shown in the table above. But, unfortunately, it is not guaranteed to find the best model (or even good models). \n",
    "\n",
    "It starts with the **null model** (i.e., a model with no covariates, only the intercept $\\beta_0$):\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = \\beta_0 + \\epsilon\n",
    "$$\n",
    "\n",
    "Then, among the remaining variables, it searches for the one that improves the model the most and incorporates the variable into the model. It keeps incorporating one variable at a time until there's no variable left that would improve the model. \n",
    "\n",
    "But what do we mean by \"improves the model the most?\" \n",
    "\n",
    "- One can use different criteria to \"measure\" this. Common choices are $C_p$, *AIC*, *BIC*, *F-statistic*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a532cba-8c6b-4202-8473-ffb06ebe6bb4",
   "metadata": {},
   "source": [
    "### 2.1.2 Simulation Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa53936-efcb-44e8-85b5-45a438aa99fe",
   "metadata": {},
   "source": [
    "We will explore if the forward selection strategy affects the model inference. For this purpose, we are going to use simulation for us to know the truth. Here's what we are going to do: \n",
    "\n",
    "1. We will consider a response variable $Y$ and $p=10$ covariates. However, none of the covariates will affect $Y$; they are all independent. (we already know the truth)\n",
    "\n",
    "\n",
    "2. Generate 100 observations of each variable from a normal distribution.\n",
    "\n",
    "\n",
    "3. Apply only the first step of forward selection. In other words, we want to add the first variable only among ten potential candidates.\n",
    "    - The metric we are going to use is the F statistic.\n",
    "\n",
    "\n",
    "4. `replicate` this study 1,000 times and measure the errors.\n",
    "\n",
    "We have already simulated the data for you (Steps 1 and 2 above) in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ca72f-ad9c-4637-ac82-635756fc508a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8196a2c8170de40f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing \n",
    "set.seed(20240214)\n",
    "\n",
    "n <- 100    # sample size\n",
    "p <- 10     # number of variables\n",
    "rep <- 500 # number of replications\n",
    "\n",
    "means <- runif((p+1), 3, 10) # the mean that will be used in the \n",
    "                             # Normal distribution for simulation.\n",
    "                             # The +1 refers to Y.  \n",
    "\n",
    "dataset <- as_tibble(\n",
    "  data.frame(\n",
    "    matrix(\n",
    "      round(rnorm((p + 1) * n * rep, \n",
    "            means, 10), 2), \n",
    "      ncol = p+1, \n",
    "      byrow = TRUE\n",
    "    )\n",
    "  ) %>%\n",
    "  rename(Y = X11) %>%\n",
    "  mutate(replicate = rep(1:rep, n)) %>%\n",
    "  arrange(replicate) \n",
    ")\n",
    "\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63562a-4fe5-4a4b-8101-38f2b777e5c0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f2f7877c77c43b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To help speed things up, we created a function for you that receives a data frame, performs the first forward selection step, and returns the F-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e0e40-555c-4656-b5f7-ed5fa58233d7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f182e694b49e309e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "forward_selection_step1 <- function(dataset){\n",
    "    #' Returns the F-statistic of the first\n",
    "    #' step of forward selection.\n",
    "    #'\n",
    "    #' @param dataset the dataset to be used\n",
    "\n",
    "    selected_model <- lm(Y ~ ., data = dataset[,c(paste(\"X\", 1, sep = \"\"), \"Y\")])\n",
    "    F_selected <- glance(selected_model) %>% pull(statistic)\n",
    "    \n",
    "    for( j in 2:(ncol(dataset)-1) ){ # fits one lm for each covariate and calculate the F statistic \n",
    "        model <- lm(Y ~ ., data = dataset[,c(paste(\"X\",j, sep = \"\"), \"Y\")])\n",
    "        F <- glance(model) %>% pull(statistic)\n",
    "        \n",
    "        \n",
    "        if (F > F_selected){\n",
    "            F_selected <- F\n",
    "            selected_model <- model\n",
    "        }\n",
    "    }\n",
    "    return(selected_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f1306-8e9f-40b9-981f-71ed683b4468",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e2ca8b6be7d1c675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise: Obtaining the forward selection model**<br>\n",
    "\n",
    "Using the `dataset` tibble, obtain the forward selection model and store the model in a column named `fs_model`. Then, extract the F-statistic from the model and store it in a column named `F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ded99a-c8c1-4ae5-896e-e23b4b3d2d34",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf37cd17c298bbb8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# forward_selection_F <- \n",
    "#     dataset %>% \n",
    "#     group_by(...) %>%\n",
    "#     nest() %>%\n",
    "#     mutate(\n",
    "#         ... = map(...), \n",
    "#         ... = ..._dbl(...)\n",
    "#     )\n",
    "\n",
    "head(forward_selection_F, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565f771-0dda-41cd-8eeb-7fad7ac44caf",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-baa571c624ad81d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question** \n",
    "\n",
    "Suppose we want to test, at 5% significance, whether the decrease in the RSS was significant by adding the variable chosen by the forward selection strategy. In this case, $\\text{F-statistic}\\sim F_{1,98}$. \n",
    "\n",
    "\n",
    "What value should we compare the F-statistic against? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4f590-3d71-4333-b12e-7ba1b05c9a76",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-63ecf21e457d958b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# F_critical <- ...\n",
    "\n",
    "F_critical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca9701-c192-4306-a8a3-f305f7021339",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4f15d48f178784a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question** \n",
    "\n",
    "Knowing that none of our covariates are relevant to model $Y$, if we use the `F_critical` you calculated in the previous question, what proportions of replications would you expect to wrongly reject the null hypothesis that the variable is not significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f8853-a18d-4c37-b144-4d29e41aa722",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-beba772a72681900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# nominal_type_I_error <- ...\n",
    "\n",
    "nominal_type_I_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f845e0-bbf4-46f6-84b8-31815d7de700",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ccc6a385e1043ed0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise** \n",
    "\n",
    "Check the proportions of F-statistics in the `forward_selection_F` tibble that are above the `F_critical` you calculated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b0493-fbb8-4a4e-b8b9-fac8bed9034d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c4e6b14508b40ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# forward_selection_type_I_error <-\n",
    "#   forward_selection_F %>%\n",
    "#   ungroup() %>%\n",
    "#   ...\n",
    "\n",
    "forward_selection_type_I_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c39a1a-af49-4a17-a3a6-3feb348a3694",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb759982412336e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Class discussion \n",
    "Contrast the `forward_selection_type_I_error` and `nominal_type_I_error`. Are they similar? Why do you think this is happening. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef43a0-a391-4a8b-ade5-bf1bffc2b195",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d34cab1fa0787324",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 The double use of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd04947-4bcf-41ae-bb56-1f5b24293b0c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7302f3b294124f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- The Type I Error after the forward selection was significantly higher than the nominal level of 5%.\n",
    "  - Well, if we are looking for the most relevant covariates **in the sample at hand**, it is not surprising that we frequently find these covariates significant.\n",
    "  - Hence, we have a much higher chance of wrongly rejecting $H_0$.  \n",
    "\n",
    "\n",
    "- Ok, we identified the problem: \n",
    "  - We use the same sample to find the variable that yields the largest test statistic and then test if the variable is relevant. \n",
    "  - You could think like this: \"We're looking at our sample to find the most relevant variable. After we find it, we will ask the same sample if the variable is relevant.\" \n",
    "\n",
    "\n",
    "- But what if we split the dataset into two parts, one for model selection and the other for inference? Would that solve the problem? Let's investigate! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36f692-83fa-44f8-b94e-86c1587adabe",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a771305759350ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- We are going to use the tibble `dataset`. But this time, we are going to split our dataset into two parts:\n",
    "  1. one for model selection \n",
    "  2. one for inference\n",
    "\n",
    "Here's what you need to do: \n",
    "\n",
    "1. Shuffle the dataset so we know that the observations are in random order. \n",
    "\n",
    "2. Using the first 50 observations, apply the first step of forward selection; store the selected model in `fs_model` column. Also, extract the F-statistic of the `fs_model` and store it in a column called `F_fs`.\n",
    "\n",
    "3. Fit the model selected in Step 2 using the 50 remaining observations and save it in a column named `inference_model`. Also, extract the F-statistic of the `inference_model` and store it in a column called `F_inference`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cf37b-14f8-4e92-a095-e1a719bc94b5",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b544356ca3740453",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(20240214) # Do not change this.\n",
    "\n",
    "# fs_error_split <- \n",
    "#     dataset %>% \n",
    "#     slice_sample(...) %>%\n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     mutate(\n",
    "#         fs_model = ...(..., .f = function(d) forward_selection_step1(d %>% head(50))), \n",
    "#         F_fs = ...,\n",
    "#         inference_model = map2(.x = ..., .y = ..., ~ update(.y, .~., data = .x %>% tail(50))), \n",
    "#         F_inference =  ...)\n",
    "#     )\n",
    "        \n",
    "head(fs_error_split) %>% \n",
    "    select(F_fs, F_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e64f6b-bae8-4435-852b-551bfdd5e5a3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d98b56dbc789635d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question** \n",
    "\n",
    "Check the proportions of F-statistics in the `F_inference` column that are above the `F_critical` you calculated. (Hint: in this case $\\text{F-statistic}\\sim F_{1,48}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbcb44-4989-412a-8168-320779c51f1a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d63bd5b3efb2ae77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# fs_split_type_I_error <- \n",
    "#   fs_error_split %>%\n",
    "#   ungroup() %>%\n",
    "#   ...\n",
    "\n",
    "fs_split_type_I_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646d377-2cc5-44c4-85ce-7a0c394f5b8d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-851de6eae8846cad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**\n",
    "\n",
    "True or false?\n",
    "\n",
    "If split the data into model selection and inference split, the type I error of the F-test after the forward selection is close to the significance level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b157bb1-83fa-4356-9b0c-20a5670fb377",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f1a4e23880603605",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# answer2.4 <- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061d3fe-e4ef-4bee-a0dc-a8f62a95e763",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Model Selection and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df148352-2ab2-415e-87ca-e8e04f3b6461",
   "metadata": {},
   "source": [
    "- A similar problem occurs when we are focused on prediction. \n",
    "\n",
    "\n",
    "- We learn to use the sample to estimate quantities of the population. \n",
    "  - It's only natural for us to think of using the in-sample MSE to estimate the out-of-sample MSE. \n",
    "  \n",
    "\n",
    "\n",
    "- The problem is that we fit our model to minimize the in-sample MSE.\n",
    "  - For this reason, the in-sample MSE tends to underestimate the out-of-sample MSE (sometimes by a considerable amount). \n",
    "  - This is called \"overfitting\" -- when your in-sample cost function is much lower than the out-of-sample cost function. \n",
    " \n",
    "\n",
    "\n",
    "  \n",
    "- To obtain a reliable estimate of the out-of-sample error, we need to predict observations the model didn't have access to during the fitting process.   \n",
    "  \n",
    " \n",
    "\n",
    "\n",
    "- To solve this problem, we resort again to data split. \n",
    "  - We split our sample into two sets, one for model fitting and one for testing the model.\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b05e0-1248-4238-ac6f-b7020c787b07",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "\n",
    "- With the split of the sample into a training set and test set, we can test our model's prediction accuracy. \n",
    "\n",
    "\n",
    "- But what about model selection? \n",
    "\n",
    "\n",
    "- Imagine you have ten competing models. You want to select the one with the best prediction accuracy. How would you do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409a640-044f-49bc-a8c6-69142145749d",
   "metadata": {},
   "source": [
    "**Approach 1**\n",
    "\n",
    "1. We use the training set to fit the models.\n",
    "2. We select the model with the best prediction accuracy in the training set.\n",
    "3. We test the model in the test set to obtain an estimate of the out-of-sample error of the selected model. \n",
    "\n",
    "<p style=\"color: red;\">What do you think of this approach? </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc82c2ad-5f29-4e29-ab1b-2615f823db69",
   "metadata": {},
   "source": [
    "**Approach 2**\n",
    "\n",
    "1. We use the training set to fit the models;\n",
    "2. We assess each model prediction accuracy in the test set; \n",
    "3. The most accurate model in the test set wins. \n",
    "\n",
    "<p style=\"color: red;\">What do you think of this approach? </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92d3cc-d565-4dac-85e4-3c032d824a90",
   "metadata": {},
   "source": [
    "#### 3.1 The validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef6b8c-4b21-4efd-8c4f-e14b4e883477",
   "metadata": {},
   "source": [
    "- The validation set is a second split of the training data.\n",
    "\n",
    "\n",
    "- We end up with three data sets: (1) training set; (2) validation set; and (3) test set;\n",
    "  1. We use the training set to fit as many models as we want;\n",
    "  2. We compare the out-of-sample models' performance using the validation set;\n",
    "  3. Once we have a winner, we estimate the out-of-sample performance using the test set.\n",
    "  \n",
    "<p style=\"color: red;\">Why can't we use the out-of-sample performance from the validation set as our estimate?</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
